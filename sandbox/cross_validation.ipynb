{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vocal-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numerapi\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "automatic-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_round = 254\n",
    "directory = f'../round{current_round}/data'\n",
    "\n",
    "with open('../dtypes.json') as f:\n",
    "    dtypes = json.load(f)\n",
    "\n",
    "full_path = f\"{directory}/numerai_dataset_{current_round}/\"\n",
    "train_path = full_path + \"numerai_training_data.csv\"\n",
    "test_path = full_path + \"numerai_tournament_data.csv\"\n",
    "train = pd.read_csv(train_path, dtype=dtypes)\n",
    "test = pd.read_csv(test_path, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "applicable-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = train#.append(test).reset_index(drop=True)\n",
    "full['era'] = full.era.str.extract('(\\d+|X)$', expand=False).str.zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "registered-humanity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>era</th>\n",
       "      <th>data_type</th>\n",
       "      <th>feature_intelligence1</th>\n",
       "      <th>feature_intelligence2</th>\n",
       "      <th>feature_intelligence3</th>\n",
       "      <th>feature_intelligence4</th>\n",
       "      <th>feature_intelligence5</th>\n",
       "      <th>feature_intelligence6</th>\n",
       "      <th>feature_intelligence7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_wisdom38</th>\n",
       "      <th>feature_wisdom39</th>\n",
       "      <th>feature_wisdom40</th>\n",
       "      <th>feature_wisdom41</th>\n",
       "      <th>feature_wisdom42</th>\n",
       "      <th>feature_wisdom43</th>\n",
       "      <th>feature_wisdom44</th>\n",
       "      <th>feature_wisdom45</th>\n",
       "      <th>feature_wisdom46</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n000315175b67977</td>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n0014af834a96cdd</td>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n001c93979ac41d4</td>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n0034e4143f22a13</td>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n00679d1a636062f</td>\n",
       "      <td>0001</td>\n",
       "      <td>train</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   era data_type  feature_intelligence1  \\\n",
       "0  n000315175b67977  0001     train                   0.00   \n",
       "1  n0014af834a96cdd  0001     train                   0.00   \n",
       "2  n001c93979ac41d4  0001     train                   0.25   \n",
       "3  n0034e4143f22a13  0001     train                   1.00   \n",
       "4  n00679d1a636062f  0001     train                   0.25   \n",
       "\n",
       "   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n",
       "0                   0.50                   0.25                   0.00   \n",
       "1                   0.00                   0.00                   0.25   \n",
       "2                   0.50                   0.25                   0.25   \n",
       "3                   0.00                   0.00                   0.50   \n",
       "4                   0.25                   0.25                   0.25   \n",
       "\n",
       "   feature_intelligence5  feature_intelligence6  feature_intelligence7  ...  \\\n",
       "0                    0.5                   0.25                   0.25  ...   \n",
       "1                    0.5                   0.00                   0.00  ...   \n",
       "2                    1.0                   0.75                   0.75  ...   \n",
       "3                    0.5                   0.25                   0.25  ...   \n",
       "4                    0.0                   0.25                   0.50  ...   \n",
       "\n",
       "   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
       "0              1.00              1.00              0.75              0.50   \n",
       "1              1.00              1.00              0.00              0.00   \n",
       "2              0.25              0.50              0.00              0.00   \n",
       "3              1.00              1.00              0.75              0.75   \n",
       "4              0.75              0.75              0.25              0.50   \n",
       "\n",
       "   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n",
       "0              0.75              0.50              1.00              0.50   \n",
       "1              0.75              0.25              0.00              0.25   \n",
       "2              0.50              1.00              0.00              0.25   \n",
       "3              1.00              1.00              0.75              1.00   \n",
       "4              0.75              0.00              0.50              0.25   \n",
       "\n",
       "   feature_wisdom46  target  \n",
       "0              0.75    0.50  \n",
       "1              1.00    0.25  \n",
       "2              0.75    0.25  \n",
       "3              1.00    0.25  \n",
       "4              0.75    0.75  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sensitive-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = full[full.data_type.isin(['train', 'validation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "protecting-contrary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [f for f in train.columns if f.startswith('feature')]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "complimentary-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "welsh-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "compact-dressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"l2\",\n",
    "    \"device\": \"gpu\",\n",
    "    \"num_iterations\": 2000,\n",
    "    \"learning_rate\": 0.006,\n",
    "    \"lambda_l1\": 1.4,\n",
    "    \"lambda_l2\": 1.0,\n",
    "    \"bagging_fraction\": 0.55,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"num_leaves\": 107,\n",
    "    \"max_depth\": 15,\n",
    "    \"verbose\": 0,\n",
    "    \"random_state\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "relevant-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman(y_true, y_pred, axis=0):\n",
    "    \"\"\" Calculate Spearman correlation \"\"\"\n",
    "    return spearmanr(y_true, y_pred, axis=axis)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "seeing-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GroupKFold(n_splits=10)\n",
    "\n",
    "model = LGBMRegressor(**param)\n",
    "\n",
    "X = train[features]\n",
    "y = train.target\n",
    "groups = train.era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scores = cross_val_score(model, X, y, groups=groups, scoring=make_scorer(spearman), cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dirty-courage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03784321, 0.03493898, 0.04653282, 0.04852294, 0.03696135,\n",
       "       0.05303415, 0.04603644, 0.05357357, 0.04637529, 0.0465557 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "rapid-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarutis/miniconda3/envs/nmr/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1.4, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.4, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.55, subsample=1.0 will be ignored. Current value: bagging_fraction=0.55\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1550\n",
      "[LightGBM] [Info] Number of data points in the train set: 501808, number of used features: 310\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX 1080 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 308 dense feature groups (74.66 MB) transferred to GPU in 0.038982 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.499997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.55, bagging_freq=1, device='gpu',\n",
       "              lambda_l1=1.4, lambda_l2=1.0, learning_rate=0.006, max_depth=15,\n",
       "              metric='l2', num_iterations=2000, num_leaves=107,\n",
       "              objective='regression', random_state=0, verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t = train[train.data_type == 'train']\n",
    "model.fit(train_t[features], train_t.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "contrary-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = test[test.data_type == 'validation'].copy()\n",
    "val['prediction'] = model.predict(val[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "departmental-richmond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "era\n",
      "era121    0.043639\n",
      "era122    0.020491\n",
      "era123    0.041825\n",
      "era124    0.061213\n",
      "era125    0.022969\n",
      "era126    0.039504\n",
      "era127    0.013370\n",
      "era128    0.063521\n",
      "era129   -0.016328\n",
      "era130    0.068619\n",
      "era131    0.037344\n",
      "era132    0.068893\n",
      "era197    0.032808\n",
      "era198    0.013265\n",
      "era199   -0.026361\n",
      "era200   -0.000153\n",
      "era201    0.004489\n",
      "era202    0.037945\n",
      "era203    0.030135\n",
      "era204    0.022000\n",
      "era205    0.001084\n",
      "era206   -0.012192\n",
      "era207    0.050778\n",
      "era208    0.055984\n",
      "era209    0.042172\n",
      "era210   -0.019489\n",
      "era211   -0.025487\n",
      "era212    0.025028\n",
      "dtype: float64\n",
      "Spearman Correlation: 0.0249\n",
      "Average Payout: 0.1245\n",
      "Sharpe Ratio: 0.8725\n",
      "Mean Absolute Error (MAE): 0.1542\n",
      "Max drawdown: 0.08634456532468171\n",
      "Feature exposure: 0.0841855355399951, Max Feature Exposure: 0.3064697812725709, Square Sum: 2.411603982498413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def spearmanr(target, pred):\n",
    "    return np.corrcoef(target, pred.rank(pct=True, method=\"first\"))[0, 1]\n",
    "\n",
    "def sharpe_ratio(corrs: pd.Series) -> np.float32:\n",
    "        \"\"\"\n",
    "        Calculate the Sharpe ratio for Numerai by using grouped per-era data\n",
    "\n",
    "        :param corrs: A Pandas Series containing the Spearman correlations for each era\n",
    "        :return: A float denoting the Sharpe ratio of your predictions.\n",
    "        \"\"\"\n",
    "        return corrs.mean() / corrs.std()\n",
    "\n",
    "#https://parmarsuraj99.medium.com/evaluating-financial-machine-learning-models-on-numerai-3562da8fd90\n",
    "def calculate_feature_exposure(df, feature_names, prediction_name='prediction') -> list:\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    -----\n",
    "    feature_exposure, max_feat_exposure, square_sum_feature_exposure = calculate_feature_exposure(df, feature_names)\n",
    "    \"\"\"\n",
    "    \n",
    "    exposures = []\n",
    "    for feature_name in feature_names:\n",
    "        exposures.append(spearmanr(df[feature_name], df[prediction_name]))\n",
    "        \n",
    "    max_feat_exposure = np.max(np.abs(exposures))\n",
    "    square_sum_feature_exposure = np.sum([e**2 for e in exposures])\n",
    "    feature_exposure = np.std(exposures)\n",
    "\n",
    "    return [feature_exposure, max_feat_exposure, square_sum_feature_exposure]\n",
    "\n",
    "#Calculating Max Drawdown\n",
    "def max_drawdown(df, prediction_name='prediction', target_name='target'):\n",
    "    scores_per_era = df.groupby(\"era\").apply(\n",
    "        lambda x: spearmanr(x[prediction_name], x[target_name]))\n",
    "\n",
    "    rolling_max = (scores_per_era+1).cumprod().rolling(window=100, min_periods=1).max()\n",
    "    daily_value = (scores_per_era+1).cumprod()\n",
    "    max_drawdown = (rolling_max - daily_value).max()\n",
    "\n",
    "    return max_drawdown\n",
    "\n",
    "def evaluate(df: pd.DataFrame, features) -> tuple:\n",
    "        \"\"\"\n",
    "        Evaluate and display relevant metrics for Numerai \n",
    "\n",
    "        :param df: A Pandas DataFrame containing the columns \"era\", \"target\" and a column for predictions\n",
    "        :param pred_col: The column where the predictions are stored\n",
    "        :return: A tuple of float containing the metrics\n",
    "        \"\"\"\n",
    "        def _score(sub_df: pd.DataFrame) -> np.float32:\n",
    "            \"\"\"Calculates Spearman correlation\"\"\"\n",
    "            return spearmanr(sub_df[\"target\"], sub_df[\"prediction\"])\n",
    "\n",
    "        # Calculate metrics\n",
    "        corrs = df.groupby(\"era\").apply(_score)\n",
    "        print(corrs)\n",
    "        payout_raw = (corrs / 0.2).clip(-1, 1)\n",
    "        spearman = round(corrs.mean(), 4)\n",
    "\n",
    "        payout = round(payout_raw.mean(), 4)\n",
    "        numerai_sharpe = round(sharpe_ratio(corrs), 4)\n",
    "        mae = mean_absolute_error(df[\"target\"], df[\"prediction\"]).round(4)\n",
    "        drawdown = max_drawdown(df)\n",
    "        fe, max_fe, square_sum_fe = calculate_feature_exposure(df, features)\n",
    "\n",
    "        # Display metrics\n",
    "        print(f\"Spearman Correlation: {spearman}\")\n",
    "        print(f\"Average Payout: {payout}\")\n",
    "        print(f\"Sharpe Ratio: {numerai_sharpe}\")\n",
    "        print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "        print(f\"Max drawdown: {drawdown}\")\n",
    "        print(f\"Feature exposure: {fe}, Max Feature Exposure: {max_fe}, Square Sum: {square_sum_fe}\")\n",
    "        return spearman, payout, numerai_sharpe, mae\n",
    "        \n",
    "feature_spearman_val = [spearmanr(val[\"prediction\"], val[f]) for f in features]\n",
    "feature_exposure_val = np.std(feature_spearman_val).round(4)\n",
    "spearman, payout, numerai_sharpe, mae = evaluate(val, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "extended-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "    scores_per_era = val.groupby(\"era\").apply(\n",
    "        lambda df: spearmanr(df['prediction'], df['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "inappropriate-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "    rolling_max = (scores_per_era+1).cumprod().rolling(window=100, min_periods=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "noble-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "    daily_value = (scores_per_era+1).cumprod()\n",
    "    max_drawdown = (rolling_max - daily_value).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "informational-nomination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08634456532468171"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "classified-intervention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.017578986239771176"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-romance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
