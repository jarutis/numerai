{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "right-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "minus-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('./data/train.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lined-drunk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train         501808\n",
       "validation    137779\n",
       "Name: data_type, dtype: Int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.data_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "outside-vacation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50    320631\n",
       "0.25    127584\n",
       "0.75    127578\n",
       "1.00     31899\n",
       "0.00     31895\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "closed-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        for group in [\"intelligence\", \"wisdom\", \"charisma\", \"dexterity\", \"strength\", \"constitution\"]:\n",
    "            cols = [col for col in df.columns if group in col]\n",
    "            df[f\"feature_{group}_mean\"] = df[cols].mean(axis=1)\n",
    "            df[f\"feature_{group}_std\"] = df[cols].std(axis=1)\n",
    "            df[f\"feature_{group}_skew\"] = df[cols].skew(axis=1)\n",
    "        return df\n",
    "\n",
    "df = get_group_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "grave-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import random as rn\n",
    "ft_corr_list=rn.sample(features, 30)# #Please try other features!\n",
    "interactions = preprocessing.PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "\n",
    "interactions.fit(train[ft_corr_list], train[\"target\"])\n",
    "\n",
    "df_interact = pd.DataFrame(interactions.transform(train[ft_corr_list]))\n",
    "\n",
    "df=pd.concat([df,df_interact],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alternative-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df.data_type == 'train']\n",
    "test = df[df.data_type == 'validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "funded-manufacturer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [f for f in train.columns if type(f) == int or f.startswith('feature')]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "enabling-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "def spearman(y_true, y_pred, axis=0):\n",
    "    \"\"\" Calculate Spearman correlation \"\"\"\n",
    "    return spearmanr(y_true, y_pred, axis=axis)[0]\n",
    "\n",
    "\n",
    "def sharpe(df: pd.DataFrame, y_pred) -> np.float32:\n",
    "    \"\"\"\n",
    "    Calculate the Sharpe ratio by using grouped per-era data\n",
    "    :param df: A Pandas DataFrame containing the columns \"era\", \"target\" and \"prediction\"\n",
    "    :return: The Sharpe ratio for your predictions.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['prediction'] = y_pred\n",
    "    def _score(sub_df: pd.DataFrame) -> np.float32:\n",
    "        \"\"\" Calculate Spearman correlation for Pandas' apply method \"\"\"\n",
    "        return spearmanr(sub_df[\"target\"], sub_df[\"prediction\"])[0, 1]\n",
    "\n",
    "    corrs = df.groupby(\"era\").apply(_score)\n",
    "    return corrs.mean() / corrs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    dtrain = lgb.Dataset(train[features], label=train.target)\n",
    " \n",
    "    param = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'l2',\n",
    "        \"device\": \"gpu\",\n",
    "        \"learning_rate\": trial.suggest_uniform('learning_rate', 0.004, 0.1),\n",
    "        \"num_iterations\": 2000,\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.1, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 0.1, 10.0),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        \"max_depth\": trial.suggest_int('max_depth', 3, 20),\n",
    "        'verbose': -1,\n",
    "    }\n",
    " \n",
    "    gbm = lgb.train(param, dtrain)\n",
    "    preds = gbm.predict(test[features])\n",
    "    accuracy = spearman(test.target, preds)\n",
    "    return accuracy\n",
    " \n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)\n",
    " \n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bulgarian-baltimore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.006085005910213603,\n",
       " 'lambda_l1': 1.460802617273486,\n",
       " 'lambda_l2': 1.0611461754655795e-05,\n",
       " 'feature_fraction': 0.9969345315260029,\n",
       " 'bagging_fraction': 0.5585536563609045,\n",
       " 'bagging_freq': 1,\n",
       " 'min_child_samples': 83,\n",
       " 'num_leaves': 107,\n",
       " 'max_depth': 15}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "metropolitan-freeware",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarutis/miniconda3/envs/nmr/lib/python3.9/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 14610\n",
      "[LightGBM] [Info] Number of data points in the train set: 501808, number of used features: 793\n",
      "[LightGBM] [Info] Using GPU Device: GeForce GTX 1080 Ti, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 791 dense feature groups (379.02 MB) transferred to GPU in 0.105557 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.499997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.014911407306901088"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(train[features], label=train.target)\n",
    "\n",
    "param = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    \"device\": \"gpu\",\n",
    "    \"num_iterations\": 2000,\n",
    "    'learning_rate': 0.006085005910213603,\n",
    " 'lambda_l1': 1.460802617273486,\n",
    " 'lambda_l2': 1.0611461754655795e-05,\n",
    " 'feature_fraction': 0.9969345315260029,\n",
    " 'bagging_fraction': 0.5585536563609045,\n",
    " 'bagging_freq': 1,\n",
    " 'min_child_samples': 83,\n",
    " 'num_leaves': 107,\n",
    " 'max_depth': 15,\n",
    "    'verbose': 1,\n",
    "    \"random_state\": 0,\n",
    "}\n",
    "\n",
    "gbm = lgb.train(param, dtrain)\n",
    "preds = gbm.predict(test[features])\n",
    "accuracy = spearman(test.target, preds)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "north-nutrition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026285507606149033"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-union",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
